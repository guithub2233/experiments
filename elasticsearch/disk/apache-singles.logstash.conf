input {
  stdin {
    type => "apache"
  }
}

filter {
  grok {
    type => "apache"
    # See the following URL for a complete list of named patterns
    # logstash/grok ships with by default:
    # https://github.com/logstash/logstash/tree/master/patterns
    #
    # The grok filter will use the below pattern and on successful match use
    # any captured values as new fields in the event.
    pattern => "%{COMBINEDAPACHELOG}"

    # Store single-value fields alone, not as arrays.
    singles => true
  }

  date {
    type => "apache"
    # Try to pull the timestamp from the 'timestamp' field (parsed above with
    # grok). The apache time format looks like: "18/Aug/2011:05:44:34 -0700"
    timestamp => "dd/MMM/yyyy:HH:mm:ss Z"
  }

  mutate {
    # Strip all superfluous fields
    exclude_tags => "_grokparsefailure"

    # I don't care about ident, auth, or ZONE (timezone). 
    # 'timestamp' field already served its purpose in the date filter
    # @message is now a duplicate of the fields grok parsed out
    # and @source is mostly duplicated by @source_path and @source_host
    remove => [ "@message", "@source", "ident", "auth", "ZONE", "timestamp" ]
  }
}

output {
  elasticsearch {
    host => "127.0.0.1"
  }
}
